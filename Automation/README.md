

# Digital Twin & Automation
## Classification of 7 facial expressions & Drawing face emoticons with Manipulator

### Introduction
​	 이 Repository는 2022년도 1학기에 Digital Twin & Automation 수업의 Automation Part의 내용입니다.
​	 우리는 카메라를 통해 사용자를 **7가지의 표정으로 분석**하고, manipulator를 활용하여 분석한 감정에 해당하는 **이모티콘을 그려주는** 프로젝트를 진행했습니다.


### Overview
![image](https://user-images.githubusercontent.com/84506968/176113683-1203b68f-0ffd-4453-8deb-4568e05cae64.png)

 ​	로봇이 그림을 그리게 되는 과정은 크게 3단계로 구성되어있습니다.

 ​	**Step1)** 카메라를 통해 표정을 분류합니다.

 ​	**Step2)** 표정에 따른 명령을 로봇에 보냅니다.

 ​	**Step3)** 명령에 따른 이모티콘을 그립니다.

 ​	자세한 내용은 Contents의 튜토리얼을 통해 볼 수 있습니다.

<br/>

### Requirements
​	본 프로젝트를 위해서는 다음과 같은 것들이 필요합니다.

​	(1) Wifi 혹은 Lan케이블의 연결이 가능한 **노트북**

​	(2) 테이블에 고정이 가능한 **화이트보드**

​	(3) **보드마카**

​	(4) **Manipulator에 offset**을 줄 수 있는 부품 

<br/>

### File Description

![image](https://user-images.githubusercontent.com/84506968/176116697-aed4abe5-020c-4aaf-9a3e-ae9c0b08745f.png)

​	(1) Wifi 혹은 Lan케이블의 연결이 가능한 **노트북**

​	(2) 테이블에 고정이 가능한 **화이트보드**

​	(3) **보드마카**

<br/>

### Contents
* ##### Tutorial for Indy Hardware & Gripper Setting
  * [Reference Link](https://github.com/Yjinsu/Digital_Twin_and_Automation/blob/main/Project%232/md_files/Tutorial%20-%20Manipulator%20INDY-10%20%26%20Gripper%20VGC10.md)


* ##### Tutorial for project implementation (Pick and Place using QR Code)
  * [Reference Link](https://github.com/Yjinsu/Digital_Twin_and_Automation/blob/main/Project%232/md_files/Tutorial%20-%20%EC%9A%B0%ED%8E%B8%20%EB%B6%84%EB%A5%98%20%EA%B3%B5%EC%A0%95%20(Pick%20%26%20Place%20using%20QR%20Code).md)

