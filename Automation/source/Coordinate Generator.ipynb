{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89503aec",
   "metadata": {},
   "source": [
    "해야할거\n",
    "\n",
    "1. 이모티콘 다그리기\n",
    "\n",
    "2. 한획 이미지 만들고 확인코드 돌려서 확인\n",
    "\n",
    "3. 만든 이미지 input으로 function돌리기 그럼 csv파일 생김"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa122ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95543842",
   "metadata": {},
   "source": [
    "놀란 이모티콘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79ba75e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imge = np.ones((100, 100), dtype=np.uint8)*255 \n",
    "# h,w\n",
    "cv2.circle(imge,(50,50),20,0)\n",
    "cv2.circle(imge,(42,45),3,0)\n",
    "cv2.circle(imge,(58,45),3,0)\n",
    "cv2.ellipse(imge,(50,60),(10,6),0,10,170,1)\n",
    "cv2.ellipse(imge,(50,60),(10,6),0,170,350,1)\n",
    "\n",
    "cv2.imshow('imge',imge)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58677c7b",
   "metadata": {},
   "source": [
    "화난 / 경멸 이모티콘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea587a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "imge = np.ones((100, 100), dtype=np.uint8)*255 \n",
    "\n",
    "cv2.circle(imge,(50,50),20,0)\n",
    "cv2.line(imge,(37,40),(47,45),1)\n",
    "cv2.line(imge,(53,45),(63,40),1)\n",
    "cv2.ellipse(imge,(50,55),(10,6),0,190,110,1) # 경멸\n",
    "# cv2.ellipse(imge,(50,60),(10,6),0,180,360,1) # 화난\n",
    "cv2.imshow('imge',imge)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b4dabc",
   "metadata": {},
   "source": [
    "슬픔 이모티콘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b83ecb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imge = np.ones((100, 100), dtype=np.uint8)*255 \n",
    "\n",
    "cv2.circle(imge,(50,50),20,0)\n",
    "cv2.line(imge,(38,45),(48,45),1)\n",
    "cv2.line(imge,(41,55),(41,45),1)\n",
    "cv2.line(imge,(45,55),(45,45),1)\n",
    "\n",
    "cv2.line(imge,(52,45),(62,45),1)\n",
    "cv2.line(imge,(55,55),(55,45),1)\n",
    "cv2.line(imge,(59,55),(59,45),1)\n",
    "\n",
    "cv2.line(imge,(45,60),(55,60),1)\n",
    "\n",
    "\n",
    "cv2.imshow('imge',imge)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907a503c",
   "metadata": {},
   "source": [
    "공포 이모티콘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c696afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imge = np.ones((100, 100), dtype=np.uint8)*255 \n",
    "\n",
    "cv2.circle(imge,(50,50),20,0)\n",
    "cv2.circle(imge,(42,45),3,0)\n",
    "cv2.circle(imge,(58,45),3,0)\n",
    "cv2.circle(imge,(42,45),6,0)\n",
    "cv2.circle(imge,(58,45),6,0)\n",
    "cv2.line(imge,(45,60),(55,60),1)\n",
    "\n",
    "cv2.imshow('imge',imge)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f1c81d",
   "metadata": {},
   "source": [
    "무표정 이모티콘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50d15b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imge = np.ones((100, 100), dtype=np.uint8)*255 \n",
    "\n",
    "cv2.circle(imge,(50,50),20,0)\n",
    "cv2.line(imge,(38,45),(48,45),1)\n",
    "cv2.line(imge,(52,45),(62,45),1)\n",
    "cv2.line(imge,(45,60),(55,60),1)\n",
    "\n",
    "\n",
    "cv2.imshow('imge',imge)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76131c20",
   "metadata": {},
   "source": [
    "웃는 이모티콘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9fd5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imge = np.ones((100, 100), dtype=np.uint8)*255 \n",
    "# h,w\n",
    "cv2.circle(imge,(50,50),20,0)\n",
    "cv2.ellipse(imge,(42,45),(4,4),0,180,360,1)\n",
    "cv2.ellipse(imge,(58,45),(4,4),0,180,360,1)\n",
    "cv2.ellipse(imge,(50,55),(10,6),0,10,170,1)\n",
    "\n",
    "cv2.imshow('imge',imge)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d4ce36",
   "metadata": {},
   "source": [
    "얘로 맞는 한 획인지 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13b08042",
   "metadata": {},
   "outputs": [],
   "source": [
    "imge = np.ones((100, 100), dtype=np.uint8)*255 \n",
    "# h,w\n",
    "cv2.circle(imge,(50,50),20,0)\n",
    "\n",
    "cv2.imshow('imge',imge)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ee997cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_coordinate(img, name):\n",
    "    b, h = img.shape\n",
    "    coordinate = []\n",
    "    temp = []\n",
    "    c=1\n",
    "    fh=0\n",
    "    fh2=0\n",
    "    for i in range(b):\n",
    "        temp = []\n",
    "        for j in range(h):\n",
    "            if (img[i][j]==0) & c:\n",
    "                fb = i\n",
    "                fh = j\n",
    "                temp.append([i, j])\n",
    "                c=0\n",
    "            if (img[i][j]==0) & (j >= fh):\n",
    "                temp.append([i, j]) \n",
    "                lb = i\n",
    "                lh = j\n",
    "        try:\n",
    "            coordinate.append(temp[-1])\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "    c=1       \n",
    "    coordinate2 = []\n",
    "    for i in range(b):\n",
    "        temp = []\n",
    "        for j in range(h):\n",
    "            if (img[i][j]==0) & c:\n",
    "                fb = i\n",
    "                fh = j\n",
    "                temp.append([i, j])\n",
    "                c=0\n",
    "            if (img[i][j]==0) & (j <= fh):\n",
    "                temp.append([i, j])\n",
    "                lb = i\n",
    "                lh = j\n",
    "        try:\n",
    "            coordinate2.append(temp[0])\n",
    "        except:\n",
    "            pass\n",
    "                \n",
    "    n = len(coordinate2)\n",
    "    for i in range(n):\n",
    "        if i!=0:\n",
    "            coordinate.append(coordinate2[n-i-1])\n",
    "\n",
    "    df=pd.DataFrame(coordinate,columns=['x','y'])\n",
    "    df.to_csv(name+'.csv', index=None,columns=['x','y'])\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_rel_pos(name):\n",
    "    data = pd.read_csv(name+'.csv')\n",
    "    data1 = data.copy()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if i==0:\n",
    "            data1['x'][i] = data['x'][i] - 50\n",
    "            data1['y'][i] = data['y'][i] - 50\n",
    "        else :\n",
    "            data1['x'][i] = data['x'][i] - data['x'][i-1]\n",
    "            data1['y'][i] = data['y'][i] - data['y'][i-1]\n",
    "    data1.to_csv(name+'_rel.csv', index=None,columns=['x','y'])\n",
    "    return None\n",
    "\n",
    "def gen_rel_coordinate(img, name):\n",
    "    \n",
    "    gen_coordinate(img, name)\n",
    "    get_rel_pos(name)\n",
    "    \n",
    "    return None\n",
    "\n",
    "def gen_rel_coordinate_noncircle(img, name):\n",
    "    b, h = img.shape\n",
    "    coordinate = []\n",
    "    temp = []\n",
    "    c=1\n",
    "    fh=0\n",
    "    fh2=0\n",
    "    for i in range(h):\n",
    "        temp = []\n",
    "        for j in range(b):\n",
    "            if (img[j][i]==1):\n",
    "                fb = i\n",
    "                fh = j\n",
    "                temp.append([i, j])\n",
    "        try:\n",
    "            coordinate.append(temp[-1])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    data=pd.DataFrame(coordinate,columns=['x','y'])\n",
    "    data.to_csv(name+'.csv', index=None,columns=['x','y'])\n",
    "    data1 = data.copy()\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if i==0:\n",
    "            data1['x'][i] = data['x'][i] - 50\n",
    "            data1['y'][i] = data['y'][i] - 50\n",
    "        else :\n",
    "            data1['x'][i] = data['x'][i] - data['x'][i-1]\n",
    "            data1['y'][i] = data['y'][i] - data['y'][i-1]\n",
    "    data1.to_csv(name+'_rel.csv', index=None,columns=['x','y'])\n",
    "    return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c204c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#놀람\n",
    "imge = np.ones((100, 100), dtype=np.uint8)*255 \n",
    "# h,w\n",
    "# cv2.circle(imge,(50,50),20,0)\n",
    "# cv2.circle(imge,(42,45),3,0)\n",
    "# cv2.circle(imge,(58,45),3,0)\n",
    "# cv2.ellipse(imge,(50,60),(10,6),0,10,170,1)\n",
    "cv2.ellipse(imge,(50,60),(10,6),0,170,350,1)\n",
    "\n",
    "cv2.imshow('imge',imge)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef452e4",
   "metadata": {},
   "source": [
    "angry   disgust     fear    happy   sad     surprise    neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "900af997",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_rel_coordinate(imge, 'surprise_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "33de6210",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_rel_coordinate_noncircle(imge,'surprise_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bb9080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from deepface import DeepFace\n",
    "import keyboard\n",
    "\n",
    "from indy_utils import indydcp_client as client\n",
    "from indy_utils.indy_program_maker import JsonProgramComponent\n",
    "\n",
    "import json\n",
    "import threading\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "person_sec = 0\n",
    "Flag = False\n",
    "\n",
    "\n",
    "            \n",
    "cap = cv2.VideoCapture(0)\n",
    "with mp_face_detection.FaceDetection(\n",
    "    model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    now_image = image           #현재 프레임의 이미지를 저장함, 아래의 pooling과정에서 image를 바꾸기 때문 \n",
    "    if not success:\n",
    "      print(\"Ignoring empty camera frame.\")\n",
    "      # If loading a video, use 'break' instead of 'continue'.\n",
    "      continue\n",
    "\n",
    "    # To improve performance, optionally mark the image as not writeable to\n",
    "    # pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  #OpenCV에서 이미지를 처리하기 위해서는 BGR -> RGB\n",
    "    results = face_detection.process(image)\n",
    "\n",
    "    # Draw the face detection annotations on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  #정상적인 이미지를 보기위해 RGB -> BGR\n",
    "    max_area = 0\n",
    "    if results.detections:\n",
    "      for detection in results.detections:\n",
    "        mp_drawing.draw_detection(image, detection)\n",
    "\n",
    "        #각각의 좌표는 0~1로 이미지의 크기 640X480으로 normalize 되어있음 \n",
    "        #float 형태로 제공\n",
    "        xmin = detection.location_data.relative_bounding_box.xmin * now_image.shape[1]\n",
    "        ymin = detection.location_data.relative_bounding_box.ymin * now_image.shape[0]\n",
    "        width = detection.location_data.relative_bounding_box.width * now_image.shape[1]\n",
    "        height = detection.location_data.relative_bounding_box.height * now_image.shape[0]\n",
    "\n",
    "        left=int(xmin) \n",
    "        top=int(ymin) \n",
    "        right=int(xmin + width )\n",
    "        bottom=int(ymin + height)\n",
    "        \n",
    "        if left < 0:\n",
    "          left = 0\n",
    "        if top < 0:\n",
    "          top = 0\n",
    "          \n",
    "        now_area = (abs(top-bottom))*(abs(right-left))\n",
    "        #bounding box의 부분만 가져옴\n",
    "        if now_area >= max_area :\n",
    "          croppedImage = now_image[top:bottom, left:right]\n",
    "          max_area = now_area\n",
    "\n",
    "        if keyboard.is_pressed(\"c\"):\n",
    "          print('pressed c')\n",
    "          Flag = True\n",
    "\n",
    "        if Flag == True:\n",
    "          person_sec += 1 #사람이 detection된 프레임의 수 1초에 33 frame\n",
    "          print('person_sec: ',person_sec)\n",
    "\n",
    "        if person_sec == 66:\n",
    "          Flag = False\n",
    "          save_image = croppedImage\n",
    "          person_sec = 0\n",
    "          print('Image Captured!')\n",
    "          \n",
    "          try:\n",
    "              obj1 = DeepFace.analyze(img_path = save_image, actions = ['emotion'], enforce_detection= False)\n",
    "              print('Probability =',obj1['emotion'][obj1['dominant_emotion']])\n",
    "              print(obj1['dominant_emotion'])\n",
    "              cap.release()\n",
    "              # break\n",
    "\n",
    "          except:\n",
    "              print('image should be clear')\n",
    "              cap.release()\n",
    "              break\n",
    "            \n",
    "    # Flip the image horizontally for a selfie-view display.\n",
    "    # cv2.imshow('MediaPipe Original Detection', cv2.flip(croppedImage, 1)) #카메라 끄는 것으로\n",
    "    cv2.imshow('MediaPipe Face Detection', cv2.flip(now_image, 1))\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "      break\n",
    "cap.release()\n",
    "\n",
    "print('Probability =',obj1['emotion'][obj1['dominant_emotion']])\n",
    "print(obj1['dominant_emotion'])\n",
    "\n",
    "emotion = obj1['dominant_emotion']\n",
    "probability = obj1['emotion'][obj1['dominant_emotion']]\n",
    "\n",
    "print('Probability = 48.76493215560913')\n",
    "print('neutral')\n",
    "print('Connect: Server IP (192.168.0.6)')\n",
    "print('5')\n",
    "print('7')\n",
    "print('7')\n",
    "print('20.0')\n",
    "print('0.2')\n",
    "print('[-26.73840735569649, 17.825044994513053, 73.95452216120538, 0.24137289217204558, 87.82731764387955, -26.706594334972365] [0.5970358004721451, -0.2998692314442255, 0.5077626257642516, 179.9611431411028, 0.4595841319951305, 179.9597851105418]')\n",
    "print(\"['ready', 'emergency', 'collision', 'error', 'busy', 'movedone', 'home', 'zero', 'resetting', 'teaching', 'direct_teaching']\")\n",
    "print(\"<class 'dict'>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
